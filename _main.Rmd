---
title: "Calidad del aire en Gijón"
author: "Sergio Berdiales"
site: bookdown::bookdown_site
documentclass: book
output:
  bookdown::gitbook: default
  #bookdown::pdf_book: default
---

# Introducción

Los objetivos principales de este proyecto son realizar análisis y visualizaciones de los datos de la estaciones oficiales de monitorización de la calidad del aire de la ciudad de Gijón.

Este proyecto es hermano de este otro https://bookdown.org/sergioberdiales/tfm-kschool_gijon_air_pollution/, que fue mi trabajo final del Máster de Data Science en Kschool (por eso hay algunas partes del código comentadas en inglés). En él, además de tratar los datos y realizar distintos ejercicios de visualización de los mismos ([ver visualizaciones en Tableau Public](https://public.tableau.com/profile/sergioberdiales#!/vizhome/ContaminacinaireGijn/PM10)), realicé diversos aproximaciones al problema de predicción (hasta 24 horas) de niveles de contaminación en la ciudad de Gijón (consultar [aquí](https://bookdown.org/sergioberdiales/tfm-kschool_gijon_air_pollution/forecasting-models.html)). Mi intención es continuar este proyecto de modelado de predicciones en un futuro próximo. Según vaya avanzando en ello iré incluyendo actualizaciones en este libro.

Este es un trabajo en curso. Cualquier sugerencia o aportación para mejorarlo será muy bienvenida. 




<!--chapter:end:index.Rmd-->

# Los datos

Los datos utilizados los he obtenido de la página web de trasparencia del ayuntamiento de Gijón  https://transparencia.gijon.es/. The data can be downloaded from  [here](https://transparencia.gijon.es/search/risp_dataset/page/1808-catalogo-de-datos?utf8=%E2%9C%93&search=aire+&search_sector=&search_format=&commit=Buscar&authenticity_token=j8%2F3CvCuPcDkrRe%2F1NR5RBp0t%2FOOosiA7724w3T2mB4%3D): 

I downloaded 19 csv files with air pollution and weather data of Gijón from years 2000 to 2018. I saved them in the "data" project folder.
I downloaded two more files from this web, a csv file with the description of the variables and another csv file with information about the measurement stations. 


All the data files are in the Github repository project, except the final dataset in csv format, because the Github file size limits (but there is a rds version of this file in the project folder "data_rds"). 

![Image source: "Informe de calidad del aire del Principado de Asturias (2016)".](imgs/gijon_stations_map.jpg)

  These are the original fields from the 18 csv files downloaded: 
  
* __Estación__: Station id.
* __Título__: Station name.
* __latitud__: Latitude.
* __longitud__: Longitude.
* __date_time_utc__:	Date Time UTC.
* __date_time_utc__:	Date Time UTC.
* __SO2__: SO2 concentration (µg/m³). 
* __NO__:	NO concentration (µg/m³). 
* __NO2__:	NO2 concentration (µg/m³).
* __CO__:	NO2 concentration (mg/m³).
* __PM10__:	Particulate Matter (<10 µg/m³).
* __O3__:	Ozone concentration (µg/m³).
* __dd__:	Wind direction (degrees).
* __vv__:	Wind speed (m/s).
* __TMP__:	Dry temperature (ºC).
* __HR__: Relative humidity (%rh).
* __PRB__: Atmospheric pressure (mb).
* __RS__: Solar radiation	(W/m²).
* __LL__: Rainfall (l/m²).
* __BEN__: Benzene concentration (µg/m³).
* __TOL__: Toluene concentration (µg/m³).
* __MXIL__: M-Xylene (µg/m³).
* __PM25__: Particulate Matter (<2.5 µg/m³).


  And these are the fields of the final file 'air_data_2.csv' (or 'air_data_2.rds'):

* __station__: Station id.
* __station_name__:	Station name.
* __latitude__: Latitude.
* __longitude__:	Longitude.
* __date_time_utc__:	Date Time UTC.
* __SO2__: SO2 concentration (µg/m³). 
* __NO__:	NO concentration (µg/m³). 
* __NO2__:	NO2 concentration (µg/m³).
* __CO__:	NO2 concentration (mg/m³).
* __PM10__:	Particulate Matter (<10 µg/m³).
* __O3__:	Ozone concentration (µg/m³).
* __dd__:	Wind direction (degrees).
* __vv__:	Wind speed (m/s).
* __TMP__:	Dry temperature (ºC).
* __HR__: Relative humidity (%rh).
* __PRB__: Atmospheric pressure (mb).
* __RS__: Solar radiation	(W/m²).
* __LL__: Rainfall (l/m²).
* __BEN__: Benzene concentration (µg/m³).
* __TOL__: Toluene concentration (µg/m³).
* __MXIL__: M-Xylene (µg/m³).
* __PM25__: Particulate Matter (<2.5 µg/m³).
* __station_alias__: Station alias (new variable).
* __year__: Year (new variable).
* __month__: Month (new variable).
* __week_day__: Week day (new variable).
* __hour__: Hour of the day (new variable).
* __date__: Date YYYY-MM-DD (new variable).
* __lab__: lab = working day / no_lab = no working day.
* __wd__: Wind direction in factor format.


```{r , warning= FALSE, message= FALSE}

library(tidyverse)
library(lubridate)
library(gridExtra)
library(kableExtra)

```

We can see on this image the location of each station. http://movil.asturias.es/medioambiente/articulos/ficheros/Informe%20de%20calidad%20del%20aire%20en%20Asturias%202016.pdf

![Image source: "Informe de calidad del aire del Principado de Asturias (2016)".](imgs/gijon_stations_map.jpg)

The air_data_descriptors.csv file contains information about the nature of the elements monitored by the stations. Names, descriptions and units.
```{r , warning= FALSE, message= FALSE}
variables <- read_csv('data/air_data_descriptors.csv', locale = locale(encoding = "ISO-8859-1"))
variables

```

In order to import the data from the 19 csv files we list all the files in the object data_files.

```{r warning= FALSE, message= FALSE}
data_files <- list.files(path = "data", pattern = "calidad_aire_gijon_20*")
```

Then, we map the function read_csv on this list in order to import every file and finally merge them in a unique dataframe (air_data_0) with reduce(rbind).

```{r warning= FALSE, message= FALSE}
air_data_0 <- data_files %>%
    map(function(x) {
        read_csv(paste0("./data/", x), locale = locale(encoding = "ISO-8859-1"), col_types = cols(.default = "c"))
    }) %>%
    reduce(rbind)
```
We take a look to the dataset
```{r warning= FALSE, message= FALSE}
glimpse(air_data_0)
```

```{r warning= FALSE, message= FALSE}
# Variables names changing
air_data_1 <- air_data_0 %>% rename(station = 'Estación',
                                    station_name = 'Título',
                                    date_time_utc = 'Fecha Solar (UTC)',
                                    latitude = latitud,
                                    longitude = longitud,
                                    wd = dd,
                                    ws = vv)
```

## Data cleaning

We imported all the columns as characters in order to avoid problems with the format attributions. So, we have to make now some format variable changes.

We change the date_time_utc format from character to date time.
```{r warning= FALSE, message= FALSE}

air_data_1$date_time_utc <- ymd_hms(air_data_1$date_time_utc)
```

We change the station and station_name formats from character to factor.
```{r warning= FALSE, message= FALSE}
air_data_1$station <- as.factor(air_data_1$station)
air_data_1$station_name <- as.factor(air_data_1$station_name)
```

We create a vector with all the variables we want to be numeric
```{r warning= FALSE, message= FALSE}
num <- colnames(air_data_1)[c(3, 4, 6:22)]
```
We make the conversion of this set of variables to numeric
```{r warning= FALSE, message= FALSE}
air_data_1 <- air_data_1 %>% mutate_at(num, as.numeric)
```

We create a dictionary with an alias for each station in order to add a new variable with more
convenient station names
```{r warning= FALSE, message= FALSE}
alias_dict <- data.frame(
      station = c("1", "2", "3", "4", "10", "11"),
      station_alias = c("Constitucion", "Argentina", "H. Felgueroso", "Castilla", "Montevil", "Santa Barbara")
)
```
We join the alias dictionary to the air_data_1 data frame to add the new variable to the data
set.
```{r warning= FALSE, message= FALSE}
air_data_1 <- air_data_1 %>% left_join(alias_dict, by = 'station')
```

We call the summary function to inspect the data main indicators
```{r warning= FALSE, message= FALSE}
summary(air_data_1)
```

There are several variables which minimun values are -9999.

```{r warning = FALSE, message = FALSE}

kable(air_data_1 %>% filter(SO2 == -9999 |
                              NO == -9999 |
                              NO2 == -9999 |
                              PM10 == -9999 |
                              O3 == -9999 )) %>%
                              kable_styling()

```

They are all from the same day (2000-01-27) and from the same station ('H. Felgueroso'). We replace these values by NAs.
```{r warning = FALSE, message = FALSE}

air_data_2 <- air_data_1 %>% mutate(SO2 = replace(SO2, SO2 == -9999, NA),
                                    NO = replace(NO, NO == -9999, NA),
                                    NO2 = replace(NO2, NO2 == -9999, NA),
                                    PM10 = replace(PM10, PM10 == -9999, NA),
                                    O3 = replace(O3, O3 == -9999, NA))

```


We check again the output of the summary function.

```{r warning = FALSE, message = FALSE}
summary(air_data_2)
```

Some pollutant variables have as minimum negative values. It does not make much sense. We take a look to the data in order to quantify the problem.

30 SO2 observations between 2015-12-25 and 2015-12-28 from the Montevil station:

```{r warning = FALSE, message = FALSE}
(neg_SO2 <- air_data_2 %>% filter(SO2 < 0) %>%
                          summarise(n = n()))

```

2 RS observations from the Constitucion station:

```{r warning = FALSE, message = FALSE}
(neg_RS <- air_data_2 %>% filter(RS < 0) %>%
                          summarise(n = n()))
```

27 TOL observations between the 2008-12-11 and the 2008-12-15 from the Constitucion station:

```{r warning = FALSE, message = FALSE}
(neg_TOL <- air_data_2 %>% filter(TOL < 0) %>%
                          summarise(n = n()))
```

59 MXIL observations between the 2008-12-10 and the 2008-12-15 from the Constitucion station:

```{r warning = FALSE, message = FALSE}
(neg_MXIL <- air_data_2 %>% filter(MXIL < 0) %>%
                          summarise(n = n()))
```

There are not many cases. We replace them all by NAs and call again the summary function.

```{r warning = FALSE, message = FALSE}

air_data_2 <- air_data_2 %>% mutate(SO2 = replace(SO2, SO2 < 0, NA),
                                    RS = replace(RS, RS < 0, NA),
                                    TOL = replace(TOL, TOL < 0, NA),
                                    MXIL = replace(MXIL, MXIL < 0, NA))

summary(air_data_2)


```

We take a look to the data completeness. What proportion of nas do we have by variable, station, year, etc?
```{r warning = FALSE, message = FALSE}

data_completeness <- air_data_2 %>%
  group_by(station_alias, year = year(date_time_utc)) %>%
  summarise_all(funs(round(sum(!is.na(.))/n(), 2))) %>% # We obtain the proportion of 'not NAs'
  select(-c(3:7, 25:28)) # These columns do not have any na. We exclude them.

head(data_completeness, 10) %>%
  kable() %>%
  kable_styling()
```

We are going to check the data completeness by station:

Constitución: There is data registered from the variables SO2, NO, NO2, CO, PM10, 03, dd, vv, TMP,  HR, PRB, HS and LL since the year 2000.
There are measurements of the variables BEN, TOL and MXIL since the year 2006 (only 0.01% ). The PM25 particles are monitored since the year 2008 (2008: only covered 0,02% of the year).
During the year 2008 the completeness of several variables (HR, PRB, HS, LL, BEN, TOL y MXIL) decrease until 88% (to do: check there was not caused by a data importing problem.)
```{r warning = FALSE, message = FALSE}
constitucion_data <- data_completeness %>% filter(station_alias == 'Constitucion')
constitucion_data %>%
                  kable() %>%
                  kable_styling()
```

Argentina: data since the year 2000. Variables: SO2, NO, NO2, CO, PM10 and 03.
```{r warning = FALSE, message = FALSE}
argentina_data <- data_completeness %>% filter(station_alias == 'Argentina')
argentina_data %>%
            kable() %>%
            kable_styling()
```

H. Felgueroso: data since the year 2000. Variables: SO2, NO, NO2, CO, PM10 and 03. During the year 2006 the completeness of the data decrease until 88% (to do: check there was not caused by a data importing problem.)
```{r warning = FALSE, message = FALSE}
felgueroso_data <- data_completeness %>% filter(station_alias == 'H. Felgueroso')

felgueroso_data %>%
        kable() %>%
        kable_styling()
```

Castilla: data since the year 2000. Variables: SO2, NO, NO2, CO, PM10 and 03. During the year 2015 the completeness of the data decrease until 77% (to do: check there was not caused by a data importing problem.)
```{r warning = FALSE, message = FALSE}
castilla_data <- data_completeness %>% filter(station_alias == 'Castilla')
castilla_data %>%
  kable() %>%
  kable_styling()
```

Montevil: Data since the year 2009. Variables: SO2, NO, NO2, 03, dd, vv, TMP, HR, PRB, HS,
LL and PM25.
```{r warning = FALSE, message = FALSE}
montevil_data <- data_completeness %>% filter(station_alias == 'Montevil')
montevil_data %>%
  kable() %>%
  kable_styling()
```

Santa Bárbara: Data since the year 2016. Variables: NO, NO2, CO, PM10, 03 and PM25
```{r warning = FALSE, message = FALSE}
barbara_data <- data_completeness %>% filter(station_alias == 'Santa Barbara')
barbara_data %>%
  kable() %>%
  kable_styling()
```

All the stations have 2019 data, but it is just 6 observations. We drop them to avoid problems when visualising the data.

```{r warning = FALSE, message = FALSE}
observations_per_year <- air_data_2 %>% group_by(year = year(date_time_utc)) %>%
                        summarise(n = n())
observations_per_year %>%
  kable() %>%
  kable_styling()
```

```{r warning = FALSE, message = FALSE}
air_data_2$year <- year(air_data_2$date_time_utc)
air_data_2 <- air_data_2 %>% filter(year != '2019')

```

## Adding new variables

### Time variables
We add to the dataset several more time variables.

```{r warning = FALSE, message = FALSE}

air_data_2$month <- month(air_data_2$date_time_utc)
air_data_2$date <- as.Date(air_data_2$date_time_utc)
air_data_2$week_day <- wday(air_data_2$date_time_utc, week_start = getOption("lubridate.week.start", 1))
air_data_2$hour <- hour(air_data_2$date_time_utc)

```

### Laboral dates

And we add a variable with the with the 'non-working days' of Gijon city from 2014 to 2017 (pendiente añadir 2018).

```{r warning = FALSE, message = FALSE}

holydays <- read_csv('data/holiday_dates.csv', locale = locale(encoding = "ISO-8859-1"))

air_data_2 <- left_join(air_data_2, holydays, by = c("date" = "holiday_date"))

air_data_2 <- air_data_2 %>%  mutate(no_lab_days = ifelse((week_day < 6 & !is.na(holiday_type)) |
                                                    (week_day >=6), "no_lab", "lab")) %>%
                                                     mutate(no_lab_days=replace(no_lab_days, date < '2014-01-01', NA))

```


### Wind direction

We create another variable to have a factor version of the 'dd' variable (wind direction in degrees).
I took this snippet of code from here:
https://community.rstudio.com/t/convert-wind-direction-degrees-into-factors-in-a-data-frame/14636/4

I made some changes because this code caused a problem when I tried to publish the document on bookdown
```{r warning = FALSE, message = FALSE}

rose_breaks <- c(0, 360/32, (1/32 + (1:15 / 16)) * 360, 360)

# The problem was the repetition of the level "N". 
# So I splited this level in two, "N1" and "N2".
rose_labs <- c(
  "N1", "NNE", "NE", "ENE",
  "E", "ES", "SE", "SSE",
  "S", "SSW", "SW", "WS",
  "W", "WNW", "NW", "NNW",
  "N2"
)

air_data_2 <- air_data_2 %>%
  mutate(
    wd_code = cut(
      wd,
      breaks = rose_breaks,
      labels = rose_labs,
      right = FALSE,
      include.lowest = TRUE
    )
  )

# And I recoded to "N"
air_data_2 <- air_data_2 %>% mutate(wd_code = recode(wd_code, N1 = "N",
                                                    N2 = "N"))
```

We save the final dataset as a rds object.
```{r warning = FALSE, message = FALSE}

saveRDS(air_data_2, file = "data_rds/air_data_2.rds")

```





<!--chapter:end:01-datos.Rmd-->

# Visualizaciones

Cargamos paquetes
```{r , warning= FALSE, message= FALSE}
library(tidyverse)
library(gganimate)
library(gifski)
library(bookdown)
library(rmarkdown)
library(purrr)
library(lubridate)
library(stringr)
library(knitr)
#library(xts)
#library(zoo)
library(gridExtra)
#library(fpp2)
#library(RcppRoll)
#library(kableExtra)
options(knitr.table.format = "html")
```

Cargamos los datos
```{r , warning= FALSE, message= FALSE}
air_data_2 <- readRDS("data_rds/air_data_2.rds")
```
Echamos un vistazo a las variables

```{r , warning= FALSE, message= FALSE}
glimpse(air_data_2)
```

Obtenemos las medias anuales de todos los contaminantes por estación y las plasmamos en un gráfico para observar sus evoluciones
```{r , warning= FALSE, message= FALSE, out.width= '\\textwidth'}
# Calculamos las medias anuales
year_avgs <- air_data_2 %>% select(station_alias, date_time_utc, PM10, PM25, SO2, NO2, NO, O3, BEN, CO, MXIL, TOL) %>%
  group_by(station_alias, year = year(date_time_utc)) %>%
  summarise_all(funs(mean(., na.rm = TRUE))) %>% 
  select(-date_time_utc) # We drop this variable


# Convertimos los resultados a formato largo

year_avgs_long <- gather(year_avgs, contaminante, value, 3:length(year_avgs)) %>% 
                    filter(!(grepl('Constit', station_alias) 
                             & year == '2006' & 
                               contaminante %in% c('BEN', 'MXIL', 'TOL'))) %>%
                                # We filter this data because is only completed in 0.01%
                    filter(!(grepl('Constit', station_alias) &
                              year == '2008' & contaminante == 'PM25'))
                                # We filter this data because is only completed in 0.02%

# Finalmente representamos los indicadores generados en una tabla de gráficos

ggplot(year_avgs_long, aes(x = year, y = value)) + 
  geom_line() + 
  facet_grid(contaminante~station_alias,scales="free_y") +
   theme(axis.text = element_text(size = 6))
```

Nos quedamos sólo con el contaminante PM10
```{r , warning= FALSE, message= FALSE, out.width= '\\textwidth'}

year_avgs_long_pm10 <- year_avgs_long %>% filter(contaminante == "PM10",
                                                 station_alias != "Montevil")

ggplot(year_avgs_long_pm10, aes(x = year, y = value)) + 
  geom_line() + 
  facet_grid(contaminante~station_alias,scales="free_y") +
   theme(axis.text = element_text(size = 6)) + ylim(0, 100)

```


```{r , warning= FALSE, message= FALSE, out.width= '\\textwidth'}


ggplot(year_avgs_long_pm10, aes(x = year, y = value, group = station_alias, color = station_alias)) + 
  geom_line()  +
  ylim(0, 100)


```

La estación Argentina es la que presenta peores valores de PM10 a lo largo del tiempo. Echamos un vistazo a su evolución a través de la función 'summary'. Para ello vamos a comparar dos histogramas, uno con las frecuencias promedio horarios de PM10 de los primeros 5 años de la serie y otro con las correspondientes a los últimos 5 años.

```{r , warning= FALSE, message= FALSE, out.width= '\\textwidth'}

pm10_argentina_2000_2004 <- air_data_2 %>% 
                           select(date, 
                                   station_alias,
                                    PM10) %>%
                           filter(year(date) < "2005",
                                  station_alias == "Argentina")

pm10_argentina_2014_2018 <- air_data_2 %>% 
                           select(date, 
                                   station_alias,
                                    PM10) %>%
                           filter(year(date) > "2013",
                                  station_alias == "Argentina")


summary(pm10_argentina_2000_2004$PM10)
summary(pm10_argentina_2014_2018$PM10)

```
Como vemos en los resultados, la evolución ha sido muy importante. Durante el periodo 2000-2004 el 75% de los promedios horarios se situaban por encima de 39  µg/m³. Mientras, en los últimos 5 años, el 75% de los promedios están por debajo de 35 µg/m³.

Vamos a comparar los histogramas de frecuencias de promedios horarios de PM10 en la estación Argentina en dos periodos, los primeros 5 años de la serie 2000-2004 contra los 5 últimos años. 
```{r , warning= FALSE, message= FALSE, out.width= '\\textwidth'}


graph_1 <- ggplot(pm10_argentina_2000_2004, aes(x = `PM10`)) +
                    geom_histogram() + 
                           xlim(0, 300) +
                           labs(title = "Distribución promedios horarios PM10 estación Argentina - (2000-2004)")


graph_2 <- ggplot(pm10_argentina_2014_2018, aes(x = `PM10`)) +
                    geom_histogram() + 
                           xlim(0, 300) +
                          labs(title = "Distribución promedios horarios PM10 estación Argentina - (2014-2018)")

grid.arrange(graph_1, 
             graph_2, 
             ncol = 1) 
```
```{r , warning= FALSE, message= FALSE, out.width= '\\textwidth'}

pm10_argentina <- air_data_2 %>% 
                           select(date_time_utc, 
                                  station_alias,
                                  PM10) %>%
                           filter(station_alias == "Argentina",
                                  PM10 != "NA")

pm10_argentina_ranges <- pm10_argentina %>% 
                         mutate(rangos = if_else(PM10 <= 20, "<=20 µg/m³", 
                                         if_else(PM10 > 20 & PM10 <= 40, "(20-40] µg/m³", ">40 µg/m³")))

pm10_argentina_ranges$rangos <- factor(pm10_argentina_ranges$rangos, levels = c("<=20 µg/m³", "(20-40] µg/m³", ">40 µg/m³"))
 
pm10_argentina_ranges_conteo <- pm10_argentina_ranges %>%
                                group_by(year = year(date_time_utc), rangos) %>%
                                summarise(n = n()) %>%
                                ungroup() %>%
                                group_by(year) %>%
                                mutate(n_total_year = sum(n),
                                       prop_year = n / n_total_year)

graph_3 <- ggplot(pm10_argentina_ranges_conteo, aes(x = rangos, y = prop_year, fill = rangos)) +
                  geom_col() +
                  facet_grid(. ~year) +
                  scale_color_manual(values = c("<=20 µg/m³" = "green", "(20-40] µg/m³" = "orange", ">40 µg/m³" = "red"),
                                     aesthetics = c("colour", "fill"))


```

```{r , warning= FALSE, message= FALSE, out.width= '\\textwidth'}
graph_4  <- ggplot(pm10_argentina_ranges_conteo, aes(x = rangos, y = prop_year, fill = rangos, label = rangos)) +
                  geom_col(show.legend = FALSE) +
                  geom_text(vjust=-0.5, size = 7, face = "bold", color = "grey")+
                  scale_color_manual(values = c("<=20 µg/m³" = "green", "(20-40] µg/m³" = "orange", ">40 µg/m³" = "red"),
                                     aesthetics = c("colour", "fill")) +
                  ggtitle("Evolución PM10 - Estación Argentina (Gijón)") +
                  ylab("% rangos PM10 - Promedios horarios") +
                  xlab("Rangos de niveles de PM10-Promedios horarios") +
                  theme(axis.text=element_text(size=12),
                  axis.title=element_text(size=16,face="bold", color = "grey"),
                  plot.title=element_text(size = 20, face="bold", color = "grey"),
                  plot.subtitle = element_text(size = 40, face="bold", color = "grey"),
                  axis.text.x=element_blank(),
                  axis.ticks.x = element_blank(),
                  panel.grid.major = element_blank(),
                  panel.grid.minor = element_blank(),
                  panel.background = element_blank()) +
                  scale_y_continuous(labels = scales::percent)

graph_4
```

Los porcentajes en el eje Y sale mal, pero por lo que sea al animarlo aparece correctamente. Así que lo dejamos así.


```{r , warning= FALSE, message= FALSE, out.width= '\\textwidth'}
pm10_Argentina_2000_2018_anim <- graph_4 + transition_time(as.integer(year)) +
  labs(title = "Evolución PM10 estación Argentina (Gijón)",
        subtitle = "Año: {frame_time}")

pm10_Argentina_2000_2018_anim

anim_save("pm10_Argentina_2000_2018.gif", pm10_Argentina_2000_2018_anim)
```


<!--chapter:end:02-visualizaciones.Rmd-->

